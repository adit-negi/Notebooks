{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Checking of shapes\nprint('Number of Training Examples {}'.format(train_df.shape))\nprint('Number of Test Examples {}'.format(test_df.shape))\nprint('Train Features:\\n', train_df.columns)\nprint('Test Features\\n', test_df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n* PassengerId\nThis features just uniquely determines the passanger and will be used for identification purposes only.\n* Survived\nOur target variable. Take the values 0 and 1 where 1 corresponds to survivors.\n* Pclass \nThis variable defines class (socio-economic status) of our passenger takes values 1,2,3 \n* Name Sex Age Fare are self explanatory.\n* SibSp \nThis refers to number of siblings or spouse aboard on titanic for this person.\n* Parch\nThis refers to number of parents or children aboard on titanic for this person.\n* Cabin \nIt is the cabin number of passengers.\n* Embarked\nIt is the port of embarkation has three unique values\n    * C Cheerburg \n    * Q Queenstown\n    * S Southampton\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see Age 179/891 , Cabin 687/891 and Embarked 889/891 columns have missing values. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see Age 86/418 Fare 1/418 Cabin 327/418 has missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Combining Train And Test Datasets\nWe will be combining train_df and test_df so that whatever preprocessing we apply get applied to both of them and then we can seperate them and make predictions on test data using our model. I admit that in reality you will not have  a test dataset available to you and you will be required to build machine learning pipelines. But for my first competition I guess this is a start. I will improve the code later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_df(train_data, test_data):\n    return pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\ndef divide_df(merged_df):\n    return merged_df.loc[:890], merged_df.loc[891:].drop(['Survived'], axis=1)\n\ndf = concat_df(train_df, test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age\nMissing values in age can be best filled by using median. But median of whole dataset is not a good choice.\nWe will fill the age according to median of Pclass and Sex. As can be seen by correlation plot below.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr().abs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_by_pclass_sex = df.groupby(['Sex', 'Pclass'])[['Age']].median()\nage_by_pclass_sex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'] = df.groupby(['Sex','Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Embarked\nWe will fill the missing values of embarked feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Embarked'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Embarked'] = df['Embarked'].fillna('S') # Filling Southampton as this is the value for martha evelyn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fare\nIt is missing for only one person.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Fare'].isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the correlation table below you can see that Fare is best correlated with Pclass, Parch, Age, SibSp so we can fill this according to the median fare of the class. Let us group them by Pclass, Parch, SibSp.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fare_for_alone_traveller_of_3rd_class = df.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()[3,0,0]\ndf['Fare'] = df['Fare'].fillna(fare_for_alone_traveller_of_3rd_class)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cabin \nCabin has has about 77% of values missing. Dropping such a coloumn makes absolute sense. But still some of the cabin may have higher surival rates as the cabins represent decks in which cabins are related. Let us see the passengers distribution in cabins.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cabin_decks = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'M']\ndef map_to_deck(cabin: str) -> str:\n    for deck in cabin_decks:\n        if deck in cabin:\n            return deck\n    return cabin\ndf['Cabin'] = df['Cabin'].fillna('M')\ndf['Cabin'] = df['Cabin'].apply(map_to_deck)\ndf['Cabin'] = df['Cabin'].replace('T', 'A')\nsurvival_by_deck = {}\nfor deck, survived in zip(df['Cabin'], df['Survived']):\n    if deck == \"Missing\":\n        continue\n    if np.isnan(survived):\n        continue\n    if deck not in survival_by_deck:\n        survival_by_deck[deck] = [0,0]\n    survival_by_deck[deck][int(survived)]+=1\nfor k, v in survival_by_deck.items():\n    survival_by_deck[k] = v[1]/(v[0]+v[1])\nsns.barplot(x=list(survival_by_deck.keys()), y=list(survival_by_deck.values()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It turns out people of cabin D, B, E most likely survived whereas cabin A, G had less than 50% chance of  survival. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Pclass', 'Cabin']).size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It turns out that Cabin A, B, C was reserved for 1st class passengers.  Here we will group them according to their class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cabin'] = df['Cabin'].replace(['A', 'B', 'C'], 'ABC')\ndf['Cabin'] = df['Cabin'].replace(['D', 'E'], 'DE')\ndf['Cabin'] = df['Cabin'].replace(['F', 'G'], 'FG')\ndf['Cabin'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = divide_df(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Target Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"survived_stats = df['Survived'].value_counts().reset_index()\nplt.figure(figsize=(8,6))\nsns.barplot(x=survived_stats['index'], y=survived_stats['Survived'])\nplt.title('Survival Percentage')\ntotal = survived_stats['Survived'].sum()\nplt.xticks((0,1), ['Not Survived {:.2f}%'.format(survived_stats.loc[0,'Survived']/total), 'Survived {:.2f}%'.format(survived_stats.loc[1,'Survived']/total) ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\n\nplt.subplot(1,2,1)\nplt.title('Train set correlations')\nsns.heatmap(train_df.corr(), annot=True, linewidth=0.5, cmap='coolwarm')\n\nplt.subplot(1,2,2)\nplt.title('Test set correlations')\nsns.heatmap(test_df.corr(), annot=True, linewidth=0.5, cmap='coolwarm')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))\nplt.subplot(1,2,1)\nsns.distplot(a=train_df[train_df['Survived'] == 1]['Age'], label='Survived')\nsns.distplot(a=train_df[train_df['Survived'] == 0]['Age'], label='Not Survived')\nplt.title('Distribution of Age and Survival')\nplt.legend()\n\nplt.subplot(1,2,2)\nsns.distplot(a=train_df['Age'], label='Train Set')\nsns.distplot(a=test_df['Age'], label='Test Set')\nplt.title('Ages Test set vs train set')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.subplot(1,2,1)\nsns.distplot(a=train_df[train_df['Survived'] == 1]['Fare'], label='Survived')\nsns.distplot(a=train_df[train_df['Survived'] == 0]['Fare'], label='Not Survived')\nplt.title('Distribution of Fare and Survival')\nplt.legend()\n\nplt.subplot(1,2,2)\nsns.distplot(a=train_df['Fare'], label='Train Set')\nsns.distplot(a=test_df['Fare'], label='Test Set')\nplt.title('Fares Test set vs train set')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_data(categoryA):\n    data = train_df.groupby([categoryA, 'Survived']).size().reset_index()\n    data.rename(columns={0:'Count'}, inplace=True)\n    sns.barplot(x=categoryA, y='Count', hue='Survived', data=data)\n    plt.title('{} vs Survival'.format(categoryA))\n    \n# embarked_vs_survival = train_df.groupby(['Embarked', 'Survived']).size().reset_index()\n# embarked_vs_survival.rename(columns={0:'Count'}, inplace=True)\nplt.figure(figsize=(20,10))\nplt.subplot(2,3,1)\nplot_data('Embarked')\n\nplt.subplot(2,3,2)\nplot_data('Sex')\n\nplt.subplot(2,3,3)\nplot_data('Pclass')\n\nplt.subplot(2,3,4)\nplot_data('SibSp')\n\nplt.subplot(2,3,5)\nplot_data('Parch')\n\nplt.subplot(2,3,6)\nplot_data('Cabin')\n\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Name\nWe will extract titles from name and replace the title with name.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"titles = ['Mr', 'Mrs', 'Ms','Master', 'Dr','Miss', 'Don', 'Capt', 'Col', 'Dona', 'Rev', 'Mlle', 'Mme', 'Major', 'Jonkheer', 'Countess']\ndef to_title(name: str) -> str:\n    for title in titles:\n        if title in name:\n            return title\n    return name\ndef replace_titles(x: pd.DataFrame) -> str:\n    title=x['Title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n        return 'Mr'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\ndf['Title'] = df['Name'].apply(to_title)\ndf['Title'] = df.apply(replace_titles, axis=1)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntitle_df = df.groupby(['Title', 'Survived']).size().reset_index()\nplt.figure(figsize=(14,8))\nsns.barplot(x='Title', y=0, hue='Survived', data=title_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating new features\nA feature such as family size makes sense rather than having seperate SibSp and Parch features we will try to create such a feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Family_size'] = df['SibSp'] + df['Parch']\nfamily_size_df = df.groupby(['Family_size', 'Survived']).size()\nplt.figure(figsize=(16,10))\nsns.barplot(x='Family_size', y=0, hue='Survived', data=family_size_df.reset_index())\npercentages = []\nfor i in range(11):\n    try:\n        percentage = family_size_df.loc[(i,1.0)]/family_size_df.loc[i].sum()\n        percentages.append(percentage)\n    except:\n        percentage = 0\n        percentages.append(percentage)\nlabels = ['Size {} \\nSurvived {:.2f}%'.format(i, percentages[i]) for i in range(11)]\nplt.xticks(tuple(range(11)), labels)\nfamily_size_df.head(25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So it seems that people travelling alone has only 30% chance of surviving whereas these chances progressively improve with family sizes of 1,2,3 having percentages 55%, 58%, 72% and then as family size further increases chances of survival go kaboom","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Binning Continous Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Fare'] = pd.qcut(df['Fare'], 13)\ndf['Fare']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'] = pd.qcut(df['Age'], 10)\ndf[\"Age\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle_cols = ['Sex', 'Embarked','Title','Cabin', 'Age', 'Fare']\nfor col in le_cols:\n    df[col] = LabelEncoder().fit_transform(df[col])\ncols_to_drop = ['Name', 'Ticket']\ndf.head()\ndf = df.drop(cols_to_drop, axis=1)\ntrain_df, test_df = divide_df(df)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop(['Survived'], axis=1)\ny = train_df.Survived\nprint(X.shape, y.shape)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n# model = RandomForestClassifier(random_state=0)\n# param_grid = {\n#     'n_estimators':[50,100,150,200],\n#     'min_samples_split':[2,4,6,8],\n#     'min_samples_leaf':[1,2,4, 6],\n# }\n# clf = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='accuracy')\n# start = time.time()\n# clf.fit(X,y)\n# print('Grid Search took {}s'.format(time.time()-start))\n# print(clf.best_params_)\n# scores = cross_val_score(RandomForestClassifier(random_state = 0,**clf.best_params_,),X, y, cv=5, n_jobs=-1)\n# print('Mean Accuracy {} Mean Std. {}'.format(scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = {'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 50}\nmodel = RandomForestClassifier(random_state=0, **best_params)\nmodel.fit(X, y)\npredictions = model.predict(test_df)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PassengerId':test_df.PassengerId, 'Survived':predictions})\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}